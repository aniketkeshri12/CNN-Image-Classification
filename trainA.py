# -*- coding: utf-8 -*-
"""CS23M013.ipynb
Automatically generated by Colaboratory.
Original file is located at
    https://colab.research.google.com/drive/1jFJYSLg4i2M_PWyPNXptyw4vH0hSkI

### Importing required libraries
"""

# !pip install wandb

# from google.colab import drive
# drive.mount('/content/drive')

import matplotlib.pyplot as plt
import numpy as np
import glob
import os
import argparse
import wandb
import torch
import torchvision
import torchvision.transforms as transforms
from torchvision.datasets.utils import download_url
from torchvision import datasets
from torch.utils.data import DataLoader, ConcatDataset, random_split

train_data_directory = '/content/drive/MyDrive/Deeplearning/inaturalist_12K/train/'
test_data_directory = '/content/drive/MyDrive/Deeplearning/inaturalist_12K/val/'

"""#Loader"""

def train_load_(train_d , train__batch_size ,test__batch_size , val_Dataset , val__batch_size,boolT=True ):

    train_batch_load = DataLoader(
        train_d,
         batch_size = train__batch_size,
        shuffle=boolT)

    batch_size = test__batch_size
    test_batch_load = DataLoader(
        test_data_directory,
        batch_size,
        shuffle=boolT)

    val_batch_load = DataLoader(
        val_Dataset,
        batch_size = val__batch_size,
        shuffle=boolT)
    return train_batch_load, val_batch_load, test_batch_load

"""#Forward"""

def fn(convolutional_layer_1 ,activation_function_1 , maxpooling_layer_1 , convolutional_layer_2 ,activation_function_2 , maxpooling_layer_2 ,convolutional_layer_3 , activation_function_3 ,  maxpooling_layer_3 , convolutional_layer_4 , activation_function_4 ,maxpooling_layer_4 , convolutional_layer_5 ,activation_function_5 , maxpooling_layer_5 , fully_connected_layer_1,dropout_layer_first , fully_connected_layer_2,dropout_layer_second , _softmax, data_x):
    #layer 1
    data_x = convolutional_layer_1(data_x)
    shape_1=data_x.shape[1]
    data_x = activation_function_1(data_x)
    data_x = maxpooling_layer_1(data_x)

    #layer 2
    data_x = convolutional_layer_2(data_x)
    shape_1=data_x.shape[1]
    data_x = activation_function_2(data_x)
    data_x = maxpooling_layer_2(data_x)

    #layer 3
    data_x = convolutional_layer_3(data_x)
    shape_1=data_x.shape[1]
    data_x = activation_function_3(data_x)
    data_x = maxpooling_layer_3(data_x)

    #layer 4
    data_x = convolutional_layer_4(data_x)
    shape_1=data_x.shape[1]
    data_x = activation_function_4(data_x)
    data_x = maxpooling_layer_4(data_x)

    #layer 5
    data_x = convolutional_layer_5(data_x)
    data_x = activation_function_5(data_x)
    shape_0=data_x.shape[1]
    data_x = maxpooling_layer_5(data_x)

    shape_1=data_x.shape[1]
    shape_2=data_x.shape[2]
    shape_3=data_x.shape[3]

    shape_all=shape_1*shape_2*shape_3
    data_x = data_x.view(-1,shape_all)
    data_x = fully_connected_layer_1(data_x)
    data_x = dropout_layer_first(data_x)
    data_x = fully_connected_layer_2(data_x)
    data_x = dropout_layer_second(data_x)
    output = _softmax(data_x)

    return data_x

"""#Transform Data
"""

def transform_datasets_(train_data_directory ,train_batch_size ,test_batch_size ,val_batch_size ,val_Dataset  , train_d , image_size , mean , std , degree ):
    transformer2 = transforms.Compose([
    transforms.Resize(image_size),
    transforms.RandomHorizontalFlip(0.5),
    transforms.RandomVerticalFlip(0.02),
    transforms.RandomRotation(degree),
    transforms.ToTensor(),
    transforms.Normalize(mean, std)

    ])

    augmented_dataset = torchvision.datasets.ImageFolder(root=train_data_directory, transform=transformer2)
    aug_d= len(augmented_dataset)
    aug_d= 0.2 *aug_d
    augmented_dataset_size = int(aug_d)
    augmented_dataset, _  =  random_split(augmented_dataset, [augmented_dataset_size, len(augmented_dataset) - augmented_dataset_size])
    train__batch_size=train_batch_size
    train_d = ConcatDataset([train_d, augmented_dataset])
    test__batch_size=test_batch_size
    val__batch_size=val_batch_size
    return train_load_(train_d , train__batch_size ,test__batch_size ,val_Dataset ,val__batch_size, boolT=True)

"""## Loading the iNatuaralist Dataset"""

def data_fetch(apply_data_augmentation, train_data_directory, test_data_directory, train_batch_size, val_batch_size, test_batch_size ,image_size, mean, std):

    trans_model_1 = transforms.Compose([
        transforms.Resize(image_size),
        transforms.ToTensor(),
        transforms.Normalize(mean, std)
    ])

    train_d = torchvision.datasets.ImageFolder(root=train_data_directory, transform=trans_model_1)
    temp =len(train_d)
    temp = 0.8* temp
    degree=45
    train_d, val_Dataset = random_split(train_d, [int(temp), len(train_d) - int(temp)])
    if apply_data_augmentation== True:
      return transform_datasets_(train_data_directory ,train_batch_size ,test_batch_size ,val_batch_size , val_Dataset , train_d ,image_size , mean , std,degree)
    return train_load_(train_d , train_batch_size ,test_batch_size ,val_Dataset ,val_batch_size, boolT=True)

"""
## Setting device to cuda if available
"""

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(device)

"""# Create a CNN Model"""

class initialize_lenet_CNN(torch.nn.Module):
    def __init__(self, number_of_classes, size_of_kernel, num_of_filters, activation_function, filter_multiplier,dropout_factor):
        super(initialize_lenet_CNN, self).__init__()

        activation_map = {
        'ReLU': torch.nn.ReLU(),
        'SiLU': torch.nn.SiLU(),
        'Mish': torch.nn.Mish(),
        'GELU': torch.nn.GELU()
         }

        #layer 1
        self.convolutional_layer_1 = torch.nn.Conv2d(in_channels=3, out_channels=num_of_filters, kernel_size=size_of_kernel)
        prev_number_filters = num_of_filters
        self.size = (256-size_of_kernel)
        self.activation_function_1 = activation_map.get(activation_function, torch.nn.ReLU())
        self.maxpooling_layer_1 = torch.nn.MaxPool2d(kernel_size=size_of_kernel, stride=2)
        self.size = self.size//2
        number_filters = int(num_of_filters * filter_multiplier)

        #layer 2
        self.convolutional_layer_2 = torch.nn.Conv2d(in_channels=prev_number_filters, out_channels=number_filters, kernel_size=size_of_kernel)
        self.size = (self.size - size_of_kernel)
        prev_number_filters = number_filters
        number_filters = int(number_filters * filter_multiplier)
        self.activation_function_2 = activation_map.get(activation_function, torch.nn.ReLU())
        self.maxpooling_layer_2 = torch.nn.MaxPool2d(kernel_size=size_of_kernel, stride=2)
        self.size = self.size//2

        #layer 3
        self.convolutional_layer_3 = torch.nn.Conv2d(in_channels=prev_number_filters, out_channels=number_filters, kernel_size=size_of_kernel)
        self.size = (self.size - size_of_kernel)
        prev_number_filters = number_filters
        number_filters = int(number_filters * filter_multiplier)
        self.activation_function_3 = activation_map.get(activation_function, torch.nn.ReLU())
        self.maxpooling_layer_3 = torch.nn.MaxPool2d(kernel_size=size_of_kernel, stride=2)
        self.size = self.size//2 # 50 x 16 x 16

        #layer4
        self.convolutional_layer_4 = torch.nn.Conv2d(in_channels=prev_number_filters, out_channels=number_filters, kernel_size=size_of_kernel)
        self.size = (self.size - size_of_kernel) # 50 x 14 x 14
        prev_number_filters = number_filters
        number_filters = int(number_filters * filter_multiplier)
        self.activation_function_4 = activation_map.get(activation_function, torch.nn.ReLU())
        self.maxpooling_layer_4 = torch.nn.MaxPool2d(kernel_size=size_of_kernel, stride=2)
        self.size = self.size//2

        #layer 5
        self.convolutional_layer_5 = torch.nn.Conv2d(in_channels=prev_number_filters, out_channels=number_filters, kernel_size=size_of_kernel)
        self.size = (self.size - size_of_kernel)
        prev_number_filters = number_filters
        stride_size=2
        self.activation_function_5 = activation_map.get(activation_function, torch.nn.ReLU())
        self.maxpooling_layer_5 = torch.nn.MaxPool2d(kernel_size=size_of_kernel, stride=stride_size)
        self.size = self.size//stride_size


        #Need to calculate the in_features.
        self.size = self.size * self.size * prev_number_filters
        size__=self.size
        self.fully_connected_layer_1 = torch.nn.Linear(in_features=size__, out_features=size__)
        self.dropout_layer_first = torch.nn.Dropout(dropout_factor)
        self.fully_connected_layer_2 = torch.nn.Linear(in_features=size__, out_features=number_of_classes)
        dimension_=1
        self.dropout_layer_second = torch.nn.Dropout(dropout_factor)
        self._softmax = torch.nn.LogSoftmax(dim=dimension_)

    def forward(self,data_x):
      return fn(self.convolutional_layer_1 ,self.activation_function_1 , self.maxpooling_layer_1 , self.convolutional_layer_2 ,self.activation_function_2 , self.maxpooling_layer_2 , self.convolutional_layer_3 , self.activation_function_3 ,  self.maxpooling_layer_3 , self.convolutional_layer_4 , self.activation_function_4 , self.maxpooling_layer_4 , self.convolutional_layer_5 ,self.activation_function_5 , self.maxpooling_layer_5 , self.fully_connected_layer_1,self.dropout_layer_first ,  self.fully_connected_layer_2,self.dropout_layer_second ,  self._softmax , data_x)

"""# Training the model"""

def train(convolutional_neural_network, learning_rate, epochs, train_batch_load, val_batch_load,apply_wandb_log):
    loss_function = torch.nn.CrossEntropyLoss()
    epoch = 0
    optimizer = torch.optim.Adam(params=convolutional_neural_network.parameters(), lr=learning_rate, weight_decay = 1e-4)
    while epoch < epochs:

        acc_train = 0
        loss_train = 0
       
        convolutional_neural_network.train()
        for i, (images, labels) in enumerate(train_batch_load):

            images = images.to(device)
            labels = labels.to(device)

            optimizer.zero_grad()  # doing zero gradient.
            predicted_y = convolutional_neural_network(images) #forward propogation
            loss = loss_function(predicted_y, labels) # Calculating Loss
            loss.backward()  # Backward Propagation
            optimizer.step() # update rule

            loss_train =loss_train + loss.item()

            _, prediction = torch.max(predicted_y.data, 1)
            acc_train =acc_train + int(torch.sum(prediction == labels.data))

        acc_train =acc_train / len(glob.glob(train_data_directory+ '/**/*.jpg' ))
        loss_train = loss_train / len(glob.glob(train_data_directory+ '/**/*.jpg' ))
        print(f"Epochs : {epoch+1} Train Accuracy : {acc_train} Train Loss {loss_train}")

        with torch.no_grad():
            test_accuracy = 0
            test_loss = 0
            convolutional_neural_network.eval()
            for i, (images, labels) in enumerate(val_batch_load):
                images= images.to(device)

                labels =labels.to(device)
                predicted_y = convolutional_neural_network(images)

                loss = loss_function(predicted_y, labels)
                test_loss =test_loss+ loss.item()
                _, predicted = torch.max(predicted_y.data, 1)
                test_accuracy = test_accuracy + int(torch.sum(predicted == labels.data))

            test_accuracy = test_accuracy/ len(glob.glob(test_data_directory+ '/**/*.jpg' ))
            test_loss = test_loss /  len(glob.glob(test_data_directory+ '/**/*.jpg' ))

            print(f"Epochs : {epoch+1} Validation Accuracy : {test_accuracy} Validation Loss {test_loss}")
            if(apply_wandb_log):
                wandb.log({"train_accuracy": acc_train, "train_loss" : loss_train, "val_accuracy": test_accuracy, "val_error": test_loss})

        epoch += 1


def main( apply_data_augmentation ,number_of_classes, kernel_size,train_batch_size, val_batch_size, test_batch_size, num_of_filters, activation_function, filter_multiplier,learning_rate, epochs, apply_wandb_log, dropout_factor , image_size):
    mean=[0.4602, 0.4495, 0.3800]
    print("start=>")
    std=[0.2040, 0.1984, 0.1921]
    train_batch_load, val_batch_load, test_batch_load = data_fetch(apply_data_augmentation, train_data_directory, test_data_directory, train_batch_size, val_batch_size, test_batch_size ,image_size, mean , std)
    convolutional_neural_network = initialize_lenet_CNN(number_of_classes, kernel_size, num_of_filters, activation_function, filter_multiplier, dropout_factor)
    convolutional_neural_network = convolutional_neural_network.to(device)
    train(convolutional_neural_network, learning_rate, epochs, train_batch_load, val_batch_load,apply_wandb_log)
    print("Done!!")
    return convolutional_neural_network


config = {
    'name': 'cs23m013',
    'metric': {
        'goal': 'maximize',
        'name': 'val_accuracy'
        },
    "method": "random",
    "project": "Deep_Learning_A2",
    "parameters": {

         "image_size" : {
            "values": [224, 256]
        },
         "epochs": {
            "values": [5,10]
        },
        "activation_function":
        {
            "values" : ["LeakyReLU" ,"Mish", "SiLU", "GELU", "ReLU"]
        },
        "dropout_factor":
        {
            "values": [0 ,0.1 , 0.2 , 0.3, 0.4]
        },
        "num_of_filters": {
            "values": [32, 64]
        },
        "filter_multiplier": {
            "values": [0.3 , 0.4 , 0.5]
        },
        "learning_rate" : {
            "values" : [0.0001, 0.0003]
            },
        "apply_data_augmentation" : {
            "values" : [True]
            },

    }
}

"""#Plotting 3 X 10 images"""

# classes=('Amphibia','Animalia','Arachnida','Aves','Fungi','Insecta','Mammalia','Mollusca','Plantae','Reptilia')

# def my_plot_model(apply_data_augmentation ,test_batch_size ,train_batch_size , val_batch_size , number_of_classes  , kernel_size  , num_of_filters  , filter_multiplier  , learning_rate   ,epochs  ,dropout_factor  ,  activation_function  , apply_wandb_log , image_size):
#     return main(apply_data_augmentation ,number_of_classes, kernel_size,  train_data_directory, test_data_directory, train_batch_size, val_batch_size, test_batch_size, num_of_filters, activation_function, filter_multiplier, learning_rate, epochs, apply_wandb_log, dropout_factor , image_size)

# model_plot=my_plot_model(apply_data_augmentation=True , test_batch_size = 16 ,train_batch_size = 64 , val_batch_size = 16 , number_of_classes = 10 , kernel_size = 3 , num_of_filters = 32 , filter_multiplier = 1 , learning_rate = 0.001  ,epochs = 1 ,dropout_factor = 0.3 ,  activation_function = 'GELU' , apply_wandb_log = False , image_size=(256,256))

# def trans_form_image_dataset(image_size=(256, 256)):
#           transformer = transforms.Compose([
#                       transforms.Resize(image_size),
#               transforms.ToTensor(),
#                   ])
#           test_Dataset = torchvision.datasets.ImageFolder(root=test_data_directory, transform=transformer)
#           return test_Dataset

# model=model_plot
# loader_val = DataLoader(trans_form_image_dataset((256, 256)),16,True)
# model.eval()
# pridicted_label = []
# actual_label = []
# with torch.no_grad():
#     for images, _ in loader_val:
#         images = images.to(device)
#         outputs = model(images)
#         _, predicted = torch.max(outputs, 1)
#         pridicted_label.extend(predicted.cpu().numpy())


# class_of_images = [[] for _ in range(len(loader_val.dataset.classes))]
# image_count = [0] * len(class_of_images)

# with torch.no_grad():
#     for img, label in loader_val:
#         for image, label in zip(img, label):
#             if image_count[label] <= 2:
#                 class_of_images[label].append(image)
#                 actual_label.append(label)
#                 image_count[label] = image_count[label]+  1

# label_names=classes
# fig, axs = plt.subplots(10, 3, figsize=(15, 30))
# fig.tight_layout(pad=3.0)

# for idx_i in range(len(class_of_images)):
#     idx_j = 0
#     while idx_j < 3:
#         img = class_of_images[idx_i][idx_j].permute(1, 2, 0)
#         predicted_label = label_names[predicted_label[idx_i * 3 + idx_j]]
#         actual_label = label_names[actual_label[idx_i]]
#         axs[idx_i, idx_j].imshow(img)
#         axs[idx_i, idx_j].set_title(f"Actual: {actual_label} \n Predicted: {predicted_label}", fontsize=15, color='black', backgroundcolor='lightgrey', pad=11)
#         axs[idx_i, idx_j].set_xticks([])
#         axs[idx_i, idx_j].set_yticks([])
#         axs[idx_i, idx_j].spines['top'].set_color('none')
#         axs[idx_i, idx_j].spines['bottom'].set_color('none')
#         axs[idx_i, idx_j].spines['left'].set_color('none')
#         axs[idx_i, idx_j].spines['right'].set_color('none')
#         axs[idx_i, idx_j].tick_params(axis='both', which='both', length=0)
#         axs[idx_i, idx_j].set_aspect('equal')
#         axs[idx_i, idx_j].grid(color='grey', linestyle='--', linewidth=0.5)
#         idx_j = idx_j + 1

# plt.show()

"""Train"""

if __name__ == "__main__":
    parser = argparse.ArgumentParser(formatter_class=argparse.ArgumentDefaultsHelpFormatter)
    # # Implemented Arg parse to take input of the hyperparameters from the command.
    parser = argparse.ArgumentParser(description="Stores all the hyperpamaters for the model.")
    parser.add_argument("-wp" , '--wandb_project', help='Project name used to track experiments in Weights & Biases dashboard' , type=str, default='Deep_Learning_A2')
    parser.add_argument("-we", "--wandb_entity",type=str, help="Wandb Entity used to track experiments in the Weights & Biases dashboard." , default="cs23m013")
    parser.add_argument("-lg","--logger",type=bool,default=False,choices=[True,False] , help="Log to wandb or not" )
    parser.add_argument('-lr', '--learning_rate', help = 'Learning rate used to optimize model parameters', type=float, default=0.001)
    parser.add_argument("-tsbs","--test_batch_size",type=int,default=16)
    parser.add_argument('-ac', '--activation', help='choices: ["LeakyReLU" ,"Mish", "SiLU", "GELU", "ReLU"]', choices = ["LeakyReLU" ,"Mish", "SiLU", "GELU", "ReLU"],type=str, default='ReLU')
    parser.add_argument("-df", "--dropout_factor", help="Dropout factor" , default=0.3, type=float)
    parser.add_argument("-ff", "--filter_multiplier",default="1", type=float, choices=[1, 0.5, 2])
    parser.add_argument("-nc","--number_of_classes",type=int,default=10)
    parser.add_argument("-ks","--kernel_size",type=int,default=3)
    parser.add_argument("-nf", "--num_filters",default="3", type=int, help="Number of filters in the convolutianal neural network.")
    parser.add_argument("-trbs","--train_batch_size",type=int,default=64)
    parser.add_argument("-vbs","--val_batch_size",type=int,default=16)
    parser.add_argument("-imgs","--image_size",type=int,default=256 , choices=[246,256])
    parser.add_argument("-aug","--apply_data_augmentation",type=bool,default=True , choices=[True,False])
    parser.add_argument('-ep', '--epochs', help="Number of epochs to train neural network.", type=int, default=3)
    parser.add_argument('-trd', '--train_data_directory', help="Dataset", type=str, default='/content/drive/MyDrive/Deeplearning/inaturalist_12K/train/')
    parser.add_argument('-tsd', '--test_data_directory', help="Dataset", type=str, default='/content/drive/MyDrive/Deeplearning/inaturalist_12K/val/')

    args = parser.parse_args()
    print("WandbProject:", args.wandb_project)
    print("Wandb Entity:", args.wandb_entity)
    print("Activation:", args.activation )
    print("Epochs:" ,args.epochs )
    print("Number of filter:" ,args.num_filters )
    print("Learning rate:", args.learning_rate)
    print("Dropout factor:" ,args.dropout_factor )
    print("Num factor:" , args.filter_multiplier)

    sweep_id = wandb.sweep(config, project=args.wandb_project)
    print('sweep_id', sweep_id)
    if(args.logger):
      wandb.init(config=args,project=args.wandb_project,entity=args.wandb_entity,reinit='true')
    main(args.apply_data_augmentation ,args.number_of_classes , args.kernel_size , args.train_batch_size , args.val_batch_size , args.test_batch_size , args.num_filters,args.activation , args.filter_multiplier , args.learning_rate , args.epochs , args.logger,args.dropout_factor , (256,256))
    wandb.finish()



